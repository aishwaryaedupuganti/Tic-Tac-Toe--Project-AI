{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uQjcHcICyuWP"
      },
      "id": "uQjcHcICyuWP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tic-Tac-Toe implemantation with a human vs Min-Max AI Agent**\n",
        "Simply run the code below and follow the instructions in the terminal to play the game. The AI will determine its moves using the Min-Max algorithm, and the player will be prompted to enter their moves using the keyboard.\n",
        "   "
      ],
      "metadata": {
        "id": "xKu0k7ch7wBr"
      },
      "id": "xKu0k7ch7wBr"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "559a47ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "559a47ee",
        "outputId": "26cd9e10-b384-4328-f19b-d4b88d9672e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Tic-Tac-Toe!\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "Enter your move (0-8): 4\n",
            "  |   |  \n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "AI is making a move...\n",
            "O |   |  \n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "Enter your move (0-8): 5\n",
            "O |   |  \n",
            "---------\n",
            "  | X | X\n",
            "---------\n",
            "  |   |  \n",
            "AI is making a move...\n",
            "O |   |  \n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "  |   |  \n",
            "Enter your move (0-8): 6\n",
            "O |   |  \n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X |   |  \n",
            "AI is making a move...\n",
            "O |   | O\n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X |   |  \n",
            "Enter your move (0-8): 1\n",
            "O | X | O\n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X |   |  \n",
            "AI is making a move...\n",
            "O | X | O\n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X | O |  \n",
            "Enter your move (0-8): 8\n",
            "O | X | O\n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X | O | X\n",
            "It's a tie!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def draw_board(board):\n",
        "    print(board[0], \"|\", board[1], \"|\", board[2])\n",
        "    print(\"---------\")\n",
        "    print(board[3], \"|\", board[4], \"|\", board[5])\n",
        "    print(\"---------\")\n",
        "    print(board[6], \"|\", board[7], \"|\", board[8])\n",
        "\n",
        "def get_player_move(board):\n",
        "    valid_move = False\n",
        "    while not valid_move:\n",
        "        move = input(\"Enter your move (0-8): \")\n",
        "        if move.isdigit() and int(move) >= 0 and int(move) <= 8 and board[int(move)] == \" \":\n",
        "            valid_move = True\n",
        "        else:\n",
        "            print(\"Invalid move, try again.\")\n",
        "    return int(move)\n",
        "\n",
        "def get_ai_move(board):\n",
        "    best_score = -float(\"inf\")\n",
        "    best_move = None\n",
        "    for i in range(9):\n",
        "        if board[i] == \" \":\n",
        "            board[i] = \"O\"\n",
        "            score = min_max(board, False)\n",
        "            board[i] = \" \"\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_move = i\n",
        "    return best_move\n",
        "\n",
        "def min_max(board, is_maximizing):\n",
        "    if check_winner(board):\n",
        "        if is_maximizing:\n",
        "            return -1\n",
        "        else:\n",
        "            return 1\n",
        "    elif check_tie(board):\n",
        "        return 0\n",
        "    elif is_maximizing:\n",
        "        best_score = -float(\"inf\")\n",
        "        for i in range(9):\n",
        "            if board[i] == \" \":\n",
        "                board[i] = \"O\"\n",
        "                score = min_max(board, False)\n",
        "                board[i] = \" \"\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "        return best_score\n",
        "    else:\n",
        "        best_score = float(\"inf\")\n",
        "        for i in range(9):\n",
        "            if board[i] == \" \":\n",
        "                board[i] = \"X\"\n",
        "                score = min_max(board, True)\n",
        "                board[i] = \" \"\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "        return best_score\n",
        "\n",
        "def check_winner(board):\n",
        "    for i in range(3):\n",
        "        if board[i] != \" \" and board[i] == board[i + 3] and board[i] == board[i + 6]:\n",
        "            return True\n",
        "    for i in range(0, 9, 3):\n",
        "        if board[i] != \" \" and board[i] == board[i + 1] and board[i] == board[i + 2]:\n",
        "            return True\n",
        "    if board[0] != \" \" and board[0] == board[4] and board[0] == board[8]:\n",
        "        return True\n",
        "    if board[2] != \" \" and board[2] == board[4] and board[2] == board[6]:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def check_tie(board):\n",
        "    return not \" \" in board\n",
        "\n",
        "\n",
        "def play_game():\n",
        "    board = [\" \" for _ in range(9)]\n",
        "    player_turn = random.choice([True, False])\n",
        "    print(\"Welcome to Tic-Tac-Toe!\")\n",
        "    draw_board(board)\n",
        "    while True:\n",
        "        if player_turn:\n",
        "            move = get_player_move(board)\n",
        "            board[move] = \"X\"\n",
        "        else:\n",
        "            print(\"AI is making a move...\")\n",
        "            move = get_ai_move(board)\n",
        "            board[move] = \"O\"\n",
        "        draw_board(board)\n",
        "        if check_winner(board):\n",
        "            if player_turn:\n",
        "                print(\"Congratulations! You win!\")\n",
        "            else:\n",
        "                print(\"Sorry, the AI wins.\")\n",
        "            break\n",
        "        elif check_tie(board):\n",
        "            print(\"It's a tie!\")\n",
        "            break\n",
        "        player_turn = not player_turn\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    play_game()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explanation**\n",
        "The minimax algorithm is used in the implementation to determine the best move for the computer player. The minimax algorithm is a recursive function that explores all possible game states and chooses the best move for the computer player. The \"O\" symbol represents the computer player.\n",
        "\n",
        "Several functions are defined in the code:\n",
        "\n",
        "\n",
        "\n",
        "draw_board: prints the game board's current state to the console.\n",
        "\n",
        "\n",
        "\n",
        "get_player_move: asks the human player for their move, validates the input, and returns the chosen move as an integer.\n",
        "\n",
        "\n",
        "\n",
        "get_ai_move: employs the minimax algorithm to determine the best move for the computer player and returns the result as an integer.\n",
        "The recursive function that implements the minimax algorithm is min_max(board, is_maximizing). Returns the current game state's score, with positive scores indicating a computer player's winning position, negative scores indicating a human player's winning position, and zero indicating a tie.\n",
        "\n",
        "check_winner: determines whether either player has won the game by examining all possible winning cell combinations.\n",
        "\n",
        "check_tie: determines whether the game is a tie by examining whether all cells are filled.\n",
        "\n",
        "Finally, the code defines the play_game() function, which initializes the game board, picks a starting player at random, and loops through each turn until a winner is determined or the game ends in a tie. After each turn, the game state is printed to the console, and the winner is announced at the end. The check name == \"main\" at the end of the code ensures that the game is only played if the code is run as a standalone program rather than as a module.\n"
      ],
      "metadata": {
        "id": "DYnWaxdszJnC"
      },
      "id": "DYnWaxdszJnC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A human's implementation of a Tic-Tac-Toe game against an AI agent using Alpha-Beta pruning:**"
      ],
      "metadata": {
        "id": "_jxylf800-bK"
      },
      "id": "_jxylf800-bK"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7636a5d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7636a5d3",
        "outputId": "b18e9c33-3dcb-4c86-ee91-59ec7e468c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Tic-Tac-Toe!\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "AI is making a move...\n",
            "O |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "Enter your move (0-8): 4\n",
            "O |   |  \n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "AI is making a move...\n",
            "O | O |  \n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "Enter your move (0-8): 2\n",
            "O | O | X\n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "AI is making a move...\n",
            "O | O | X\n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "O |   |  \n",
            "Enter your move (0-8): 3\n",
            "O | O | X\n",
            "---------\n",
            "X | X |  \n",
            "---------\n",
            "O |   |  \n",
            "AI is making a move...\n",
            "O | O | X\n",
            "---------\n",
            "X | X | O\n",
            "---------\n",
            "O |   |  \n",
            "Enter your move (0-8): 8\n",
            "O | O | X\n",
            "---------\n",
            "X | X | O\n",
            "---------\n",
            "O |   | X\n",
            "AI is making a move...\n",
            "O | O | X\n",
            "---------\n",
            "X | X | O\n",
            "---------\n",
            "O | O | X\n",
            "It's a tie!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def draw_board(board):\n",
        "    print(board[0], \"|\", board[1], \"|\", board[2])\n",
        "    print(\"---------\")\n",
        "    print(board[3], \"|\", board[4], \"|\", board[5])\n",
        "    print(\"---------\")\n",
        "    print(board[6], \"|\", board[7], \"|\", board[8])\n",
        "\n",
        "def get_player_move(board):\n",
        "    valid_move = False\n",
        "    while not valid_move:\n",
        "        move = input(\"Enter your move (0-8): \")\n",
        "        if move.isdigit() and int(move) in range(9) and board[int(move)] == \" \":\n",
        "            return int(move)\n",
        "        else:\n",
        "            print(\"Invalid move, please try again.\")\n",
        "\n",
        "def check_winner(board):\n",
        "    winning_positions = [\n",
        "        (0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
        "        (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
        "        (0, 4, 8), (2, 4, 6)\n",
        "    ]\n",
        "    for a, b, c in winning_positions:\n",
        "        if board[a] == board[b] == board[c] != \" \":\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def check_tie(board):\n",
        "    return \" \" not in board\n",
        "\n",
        "def get_ai_move(board):\n",
        "    _, move = minimax(board, True, -float(\"inf\"), float(\"inf\"))\n",
        "    return move\n",
        "\n",
        "def minimax(board, is_maximizing_player, alpha, beta):\n",
        "    if check_winner(board):\n",
        "        return (-1 if is_maximizing_player else 1, None)\n",
        "    elif check_tie(board):\n",
        "        return (0, None)\n",
        "\n",
        "    if is_maximizing_player:\n",
        "        best_score = -float(\"inf\")\n",
        "        for i in range(9):\n",
        "            if board[i] == \" \":\n",
        "                board[i] = \"O\"\n",
        "                score, _ = minimax(board, False, alpha, beta)\n",
        "                board[i] = \" \"\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_move = i\n",
        "                alpha = max(alpha, best_score)\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "        return (best_score, best_move)\n",
        "    else:\n",
        "        best_score = float(\"inf\")\n",
        "        for i in range(9):\n",
        "            if board[i] == \" \":\n",
        "                board[i] = \"X\"\n",
        "                score, _ = minimax(board, True, alpha, beta)\n",
        "                board[i] = \" \"\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_move = i\n",
        "                beta = min(beta, best_score)\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "        return (best_score, best_move)\n",
        "\n",
        "\n",
        "def play_game():\n",
        "    board = [\" \" for _ in range(9)]\n",
        "    player_turn = random.choice([True, False])\n",
        "    print(\"Welcome to Tic-Tac-Toe!\")\n",
        "    draw_board(board)\n",
        "    while True:\n",
        "        if player_turn:\n",
        "            move = get_player_move(board)\n",
        "            board[move] = \"X\"\n",
        "        else:\n",
        "            print(\"AI is making a move...\")\n",
        "            move = get_ai_move(board)\n",
        "            board[move] = \"O\"\n",
        "        draw_board(board)\n",
        "        if check_winner(board):\n",
        "            if player_turn:\n",
        "                print(\"Congratulations! You win!\")\n",
        "            else:\n",
        "                print(\"Sorry, the AI wins.\")\n",
        "            break\n",
        "        elif check_tie(board):\n",
        "            print(\"It's a tie!\")\n",
        "            break\n",
        "        player_turn = not player_turn\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    play_game()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explanation**\n",
        "To select who goes first at random, the random module is imported at the beginning of the function.\n",
        "\n",
        "The draw_board function prints the board's current state in a readable way after receiving a list that represents it.\n",
        "\n",
        "Once a legal move is entered, the get_player_move method asks the user for input and returns the move that was selected. An integer that falls between 0 and 8 (inclusive) that corresponds to an empty square on the board is a legitimate move.\n",
        "The function check_winner verifies if any player has won by looking at the board. It accomplishes this by examining each and every winning combination that could occur in the rows, columns, and diagonals of the board. The function returns True if any of these combinations have three instances of the same symbol (X or O). If not, False is returned.\n",
        "\n",
        "To determine whether the game has ended in a tie, the check_tie function looks over the board. When there are no more blank squares on the board, this is accurate.\n",
        "The minimax algorithm is used by the get_ai_move function to determine the optimal move for the AI player. The move that produces the best result for the AI player is determined by the minimax algorithm, a recursive function that simulates every move that could be made on the board. Both the chosen move's index and the score related to it are returned by the function.\n",
        "Recursively calling the minimax function simulates every move that could be made on the board. It receives the board state as input, a boolean value indicating whether the AI or the human player is currently maximizing or minimizing, and two parameters, alpha and beta, which are used to refine the search tree and boost algorithmic efficiency. The best move index and score are returned by the function.\n",
        "\n",
        "The player who goes first is chosen at random by the play_game function, which also initializes an empty board. The program then repeatedly runs through each turn, asking the player to input or invoking get_ai_move to determine the AI's next move. The check_winner and check_tie functions are called to ascertain whether the game has ended after the board is redrawn following each turn. In that case, the game concludes with the winner—or lack thereof—being declared. If not, the other player's turn is added to the loop.\n",
        "\n",
        "Lastly, play_game is only called if the script is executed directly, meaning it is not imported as a module, thanks to the if name == \"main\" line at the bottom of the code.\n",
        "\n"
      ],
      "metadata": {
        "id": "R12syWhR1QOL"
      },
      "id": "R12syWhR1QOL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Q-learning to implement a human-versus-AI Tic-Tac-Toe match:**"
      ],
      "metadata": {
        "id": "7Y2bY5h82cwK"
      },
      "id": "7Y2bY5h82cwK"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f878ad7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f878ad7d",
        "outputId": "01196f1a-9f60-49e7-80aa-29ef745da6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current state:\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "Enter row and column (0-2): 0-1\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "Enter row and column (0-2): 1-1\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "Enter row and column (0-2): 1-2\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  0 -1]]\n",
            "Enter row and column (0-2): 2-1\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  1 -1]]\n",
            "Enter row and column (0-2): 2-2\n",
            "Invalid move, try again.\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  1 -1]]\n",
            "Enter row and column (0-2): 2-1\n",
            "Invalid move, try again.\n",
            "Current state:\n",
            "[[ 0 -1  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  1 -1]]\n",
            "Enter row and column (0-2): 0-0\n",
            "You lost!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Initialize Q-values\n",
        "Q = {}\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1 # learning rate\n",
        "gamma = 0.9 # discount factor\n",
        "epsilon = 0.1 # exploration probability\n",
        "\n",
        "# Define game state and action space\n",
        "state_space = [[0, 0, 0] for i in range(3)]\n",
        "action_space = [(i, j) for i in range(3) for j in range(3)]\n",
        "\n",
        "# Define reward function\n",
        "def reward(state):\n",
        "    if any(sum(row) == 3 for row in state): # check rows\n",
        "        return 1\n",
        "    if any(sum(col) == 3 for col in zip(*state)): # check columns\n",
        "        return 1\n",
        "    if sum(state[i][i] for i in range(3)) == 3: # check diagonal\n",
        "        return 1\n",
        "    if sum(state[i][2-i] for i in range(3)) == 3: # check diagonal\n",
        "        return 1\n",
        "    if any(sum(row) == -3 for row in state): # check rows\n",
        "        return -1\n",
        "    if any(sum(col) == -3 for col in zip(*state)): # check columns\n",
        "        return -1\n",
        "    if sum(state[i][i] for i in range(3)) == -3: # check diagonal\n",
        "        return -1\n",
        "    if sum(state[i][2-i] for i in range(3)) == -3: # check diagonal\n",
        "        return -1\n",
        "    return 0\n",
        "\n",
        "# Define epsilon-greedy policy\n",
        "def epsilon_greedy_policy(state, epsilon):\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        return random.choice(action_space)\n",
        "    else:\n",
        "        #q_values = [Q.get((tuple(state), action), 0) for action in action_space]\n",
        "        q_values = [Q.get((tuple(map(tuple, state)), action), 0) for action in action_space]\n",
        "        max_q_value = max(q_values)\n",
        "        count = q_values.count(max_q_value)\n",
        "        if count > 1:\n",
        "            best_actions = [action_space[i] for i in range(len(action_space)) if q_values[i] == max_q_value]\n",
        "            return random.choice(best_actions)\n",
        "        else:\n",
        "            return action_space[q_values.index(max_q_value)]\n",
        "\n",
        "# Define Q-learning algorithm\n",
        "#def q_learning(state, action, next_state, reward, alpha, gamma):\n",
        "#   max_next_q_value = max([Q.get((tuple(next_state), next_action), 0) for next_action in action_space])\n",
        "#   current_q_value = Q.get((tuple(state), action), 0)\n",
        "#    Q[(tuple(state), action)] = current_q_value + alpha * (reward + gamma * max_next_q_value - current_q_value)\n",
        "\n",
        "def q_learning(state, action, next_state, reward, alpha, gamma):\n",
        "    state = tuple(map(tuple, state))\n",
        "    next_state = tuple(map(tuple, next_state))\n",
        "    # Get Q-value for current state-action pair\n",
        "    q_value = Q.get((state, action), 0)\n",
        "    # Compute the maximum Q-value for the next state\n",
        "    #max_q_value = max([Q.get((next_state, a), 0) for a in action_space(next_state)])\n",
        "    max_q_value = max([Q.get((next_state, a), 0) for a in action_space])\n",
        "    # Update Q-value using Q-learning formula\n",
        "    #Q[(state, action)] = q_value + alpha * (reward + gamma * max_q_value - q_value)\n",
        "    Q[tuple(map(tuple, state)), action] = q_value + alpha * (reward + gamma * max_q_value - q_value)\n",
        "\n",
        "\n",
        "# Initialize game\n",
        "state = state_space.copy()\n",
        "while True:\n",
        "    # Human player's turn\n",
        "    print(\"Current state:\")\n",
        "    print(np.array(state))\n",
        "    #row, col = input(\"Enter row and column (0-2): \").split()\n",
        "    input_str = input(\"Enter row and column (0-2): \")\n",
        "    row, col = input_str.split('-') if '-' in input_str else input_str.split()\n",
        "    row, col = int(row), int(col)\n",
        "    if state[row][col] != 0:\n",
        "        print(\"Invalid move, try again.\")\n",
        "        continue\n",
        "    state[row][col] = 1\n",
        "    reward_value = reward(state)\n",
        "    if reward_value != 0:\n",
        "        print(\"You won!\")\n",
        "        break\n",
        "    if all(all(row) for row in state):\n",
        "        print(\"Tie!\")\n",
        "        break\n",
        "    # AI agent's turn\n",
        "    action = epsilon_greedy_policy(state, epsilon)\n",
        "    state[action[0]][action[1]] = -1\n",
        "    reward_value = reward(state)\n",
        "\n",
        "    if reward_value != 0:\n",
        "        print(\"You lost!\")\n",
        "        break\n",
        "    if all(all(row) for row in state):\n",
        "        print(\"Tie!\")\n",
        "        break\n",
        "\n",
        "# Update Q-values\n",
        "q_learning(state, action, state, reward_value, alpha, gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explanation**\n",
        "A few variables and functions are defined at the beginning of the program:\n",
        "\n",
        "Q: a dictionary where state-action pair Q-values are kept Alpha is the rate of learning. Gamma is the factor of discount. Epsilon: the likelihood of exploration state_space: a list that shows how the game board is currently configured action_space: a list containing every action that could be taken reward(state): a function that determines the incentive for a specific condition The function epsilon_greedy_policy(state, epsilon) applies the epsilon-greedy policy to action selection. A function called q_learning(state, action, next_state, reward, alpha, gamma) modifies the Q-value for a specific state-action pair. After initializing the game board, the program initiates a loop in which moves are made alternately by the AI agent and the human player.\n",
        "\n",
        "The program asks the user to enter the row and column of their move during the human player's turn while printing the current state of the game board. The program updates the game board and determines whether the game is over if the move is valid. The software prints the outcome and ends the loop if the game is over.\n",
        "\n",
        "The program updates the game board, checks to see if the game is over, and chooses an action based on the epsilon-greedy policy during the AI agent's turn. The software prints the outcome and ends the loop if the game is over.\n",
        "\n",
        "The software updates the Q-value for the final state-action pair by calling the q_learning() function after the game is finished."
      ],
      "metadata": {
        "id": "DA2KU1wJ23He"
      },
      "id": "DA2KU1wJ23He"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using all AI agents (MIN_MAX, ALPHA_BETA, Q-LEARNING) to implement TIC-TAC-TOE**"
      ],
      "metadata": {
        "id": "DEVvL96r3vji"
      },
      "id": "DEVvL96r3vji"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "56540eb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56540eb3",
        "outputId": "372bda4c-3ff3-4eea-d538-31e53b941976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================\n",
            "TIC-TAC-TOE using MINIMAX with MIN MAX OVER ALPHA-BETA Pruning\n",
            "=================================================\n",
            "|   ||   ||   |\n",
            "---------------\n",
            "|   || X ||   |\n",
            "---------------\n",
            "|   ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "| O ||   ||   |\n",
            "---------------\n",
            "|   || X ||   |\n",
            "---------------\n",
            "|   ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "| O || O ||   |\n",
            "---------------\n",
            "|   || X ||   |\n",
            "---------------\n",
            "|   ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "| O || O || X |\n",
            "---------------\n",
            "|   || X ||   |\n",
            "---------------\n",
            "|   ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "| O || O || X |\n",
            "---------------\n",
            "|   || X ||   |\n",
            "---------------\n",
            "| O ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "| O || O || X |\n",
            "---------------\n",
            "| O || X ||   |\n",
            "---------------\n",
            "| O ||   ||   |\n",
            "---------------\n",
            "===============\n",
            "O's have won!, Alpha Beta Pruning  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import choice\n",
        "from math import inf\n",
        "\n",
        "board = [[0, 0, 0],\n",
        "         [0, 0, 0],\n",
        "         [0, 0, 0]]\n",
        "\n",
        "def Gameboard(board):\n",
        "    chars = {1: 'X', -1: 'O', 0: ' '}\n",
        "    for x in board:\n",
        "        for y in x:\n",
        "            ch = chars[y]\n",
        "            print(f'| {ch} |', end='')\n",
        "        print('\\n' + '---------------')\n",
        "    print('===============')\n",
        "\n",
        "def Clearboard(board):\n",
        "    for x, row in enumerate(board):\n",
        "        for y, col in enumerate(row):\n",
        "            board[x][y] = 0\n",
        "\n",
        "def winningPlayer(board, player):\n",
        "    conditions = [[board[0][0], board[0][1], board[0][2]],\n",
        "                     [board[1][0], board[1][1], board[1][2]],\n",
        "                     [board[2][0], board[2][1], board[2][2]],\n",
        "                     [board[0][0], board[1][0], board[2][0]],\n",
        "                     [board[0][1], board[1][1], board[2][1]],\n",
        "                     [board[0][2], board[1][2], board[2][2]],\n",
        "                     [board[0][0], board[1][1], board[2][2]],\n",
        "                     [board[0][2], board[1][1], board[2][0]]]\n",
        "\n",
        "    if [player, player, player] in conditions:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def gameWon(board):\n",
        "    return winningPlayer(board, 1) or winningPlayer(board, -1)\n",
        "\n",
        "def printResult(board):\n",
        "    if winningPlayer(board, 1):\n",
        "        print('X has won!, Min Max  ' + '\\n')\n",
        "\n",
        "    elif winningPlayer(board, -1):\n",
        "        print('O\\'s have won!, Alpha Beta Pruning  ' + '\\n')\n",
        "\n",
        "    else:\n",
        "        print('Draw' + '\\n')\n",
        "\n",
        "def blanks(board):\n",
        "    blank = []\n",
        "    for x, row in enumerate(board):\n",
        "        for y, col in enumerate(row):\n",
        "            if board[x][y] == 0:\n",
        "                blank.append([x, y])\n",
        "\n",
        "    return blank\n",
        "\n",
        "def boardFull(board):\n",
        "    if len(blanks(board)) == 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def setMove(board, x, y, player):\n",
        "    board[x][y] = player\n",
        "\n",
        "def playerMove(board):\n",
        "    e = True\n",
        "    moves = {1: [0, 0], 2: [0, 1], 3: [0, 2],\n",
        "             4: [1, 0], 5: [1, 1], 6: [1, 2],\n",
        "             7: [2, 0], 8: [2, 1], 9: [2, 2]}\n",
        "    while e:\n",
        "        try:\n",
        "            move = int(input('Enter a number between 1-9: '))\n",
        "            if move < 1 or move > 9:\n",
        "                print('Invalid Move! Try again!')\n",
        "            elif not (moves[move] in blanks(board)):\n",
        "                print('Invalid Move! Try again!')\n",
        "            else:\n",
        "                setMove(board, moves[move][0], moves[move][1], 1)\n",
        "                Gameboard(board)\n",
        "                e = False\n",
        "        except(KeyError, ValueError):\n",
        "            print('Enter a number!')\n",
        "\n",
        "def getScore(board):\n",
        "    if winningPlayer(board, 1):\n",
        "        return 10\n",
        "\n",
        "    elif winningPlayer(board, -1):\n",
        "        return -10\n",
        "\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "class QLearningPlayer():\n",
        "    def __init__(self):\n",
        "        self.name = 'Q-Learning'\n",
        "        self.q = {}\n",
        "        self.init_q = 1 # \"optimistic\" 1.0 initial values\n",
        "        self.lr = 0.3\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 1.0\n",
        "        self.max_epsilon = 1.0\n",
        "        self.min_epsilon = 0.01\n",
        "        self.decay_rate = 0.01\n",
        "        self.action_n = 9\n",
        "        self.win_n = 0\n",
        "\n",
        "        self.last_state = (' ',) * 9\n",
        "        self.last_action = -1\n",
        "\n",
        "    def action(self, state, actions):\n",
        "        state = tuple(state)\n",
        "        self.last_state = state\n",
        "\n",
        "        r = random.uniform(0, 1)\n",
        "        if r > self.epsilon:\n",
        "            if self.q.get(state):\n",
        "                i = np.argmax([self.q[state][a] for a in actions])\n",
        "                action = actions[i]\n",
        "            else:\n",
        "                self.q[state] = [self.init_q] * self.action_n\n",
        "                action = random.choice(actions)\n",
        "        else:\n",
        "            action = random.choice(actions)\n",
        "\n",
        "        self.last_action = action\n",
        "        return action\n",
        "\n",
        "    def reward(self, reward, state):\n",
        "        if self.last_action >= 0:\n",
        "            if reward == 1:\n",
        "                self.win_n += 1\n",
        "\n",
        "            state = tuple(state)\n",
        "            if self.q.get(self.last_state):\n",
        "                q = self.q[self.last_state][self.last_action]\n",
        "            else:\n",
        "                self.q[self.last_state] = [self.init_q] * self.action_n\n",
        "                q = self.init_q\n",
        "\n",
        "            self.q[self.last_state][self.last_action] = q + self.lr * (reward + self.gamma * np.max(self.q.get(state, [self.init_q]*self.action_n)) - q)\n",
        "\n",
        "    def episode_end(self, episode):\n",
        "        # epsilon decay\n",
        "        self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon) * np.exp(-self.decay_rate*(episode+1))\n",
        "\n",
        "    def print_q(self):\n",
        "        for k,v in self.q.items():\n",
        "            print(k,v)\n",
        "\n",
        "def minimax(state, depth, player):\n",
        "    \"\"\"\n",
        "    AI function that choice the best move\n",
        "    :param state: current state of the board\n",
        "    :param depth: node index in the tree (0 <= depth <= 9),\n",
        "    but never nine in this case (see iaturn() function)\n",
        "    :param player: an human or a computer\n",
        "    :return: a list with [the best row, best col, best score]\n",
        "    \"\"\"\n",
        "    if player == -1:\n",
        "        best = [-1, -1, -10000000]\n",
        "    else:\n",
        "        best = [-1, -1, +10000000]\n",
        "\n",
        "    if depth == 0 or gameWon(state):\n",
        "        score = getScore(state)\n",
        "        return [-1, -1, score]\n",
        "\n",
        "    for cell in blanks(state):\n",
        "        x, y = cell[0], cell[1]\n",
        "        state[x][y] = player\n",
        "        score = minimax(state, depth - 1, -player)\n",
        "        state[x][y] = 0\n",
        "        score[0], score[1] = x, y\n",
        "\n",
        "        if player == -1:\n",
        "            if score[2] > best[2]:\n",
        "                best = score  # max value\n",
        "        else:\n",
        "            if score[2] < best[2]:\n",
        "                best = score  # min value\n",
        "\n",
        "    return best\n",
        "\n",
        "def abminimax(board, depth, alpha, beta, player):\n",
        "    row = -1\n",
        "    col = -1\n",
        "    if depth == 0 or gameWon(board):\n",
        "        return [row, col, getScore(board)]\n",
        "\n",
        "    else:\n",
        "        for cell in blanks(board):\n",
        "            setMove(board, cell[0], cell[1], player)\n",
        "            score = abminimax(board, depth - 1, alpha, beta, -player)\n",
        "            if player == 1:\n",
        "                # X is always the max player\n",
        "                if score[2] > alpha:\n",
        "                    alpha = score[2]\n",
        "                    row = cell[0]\n",
        "                    col = cell[1]\n",
        "\n",
        "            else:\n",
        "                if score[2] < beta:\n",
        "                    beta = score[2]\n",
        "                    row = cell[0]\n",
        "                    col = cell[1]\n",
        "\n",
        "            setMove(board, cell[0], cell[1], 0)\n",
        "\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "\n",
        "        if player == 1:\n",
        "            return [row, col, alpha]\n",
        "\n",
        "        else:\n",
        "            return [row, col, beta]\n",
        "\n",
        "def o_comp(board):\n",
        "    if len(blanks(board)) == 9:\n",
        "        #x = choice([0, 1, 2])\n",
        "        #y = choice([0, 1, 2])\n",
        "        move = minimax(board, len(blanks(board)), +1)\n",
        "        x, y = move[0], move[1]\n",
        "        setMove(board, x, y, -1)\n",
        "        Gameboard(board)\n",
        "\n",
        "    else:\n",
        "        result = abminimax(board, len(blanks(board)), -inf, inf, -1)\n",
        "        setMove(board, result[0], result[1], -1)\n",
        "        Gameboard(board)\n",
        "\n",
        "def x_comp(board):\n",
        "    if len(blanks(board)) == 9:\n",
        "        #x = choice([0, 1, 2])\n",
        "        #y = choice([0, 1, 2])\n",
        "        move = minimax(board, len(blanks(board)), +1)\n",
        "        x, y = move[0], move[1]\n",
        "        setMove(board, x, y, 1)\n",
        "        Gameboard(board)\n",
        "\n",
        "    else:\n",
        "        result = abminimax(board, len(blanks(board)), -inf, inf, 1)\n",
        "        setMove(board, result[0], result[1], 1)\n",
        "        Gameboard(board)\n",
        "\n",
        "def makeMove(board, player, mode):\n",
        "    if mode == 1:\n",
        "        if player == 1:\n",
        "            minimax(board,len(blanks(board)),player)\n",
        "\n",
        "        else:\n",
        "            o_comp(board)\n",
        "    else:\n",
        "        if player == 1:\n",
        "            o_comp(board)\n",
        "        else:\n",
        "            x_comp(board)\n",
        "\n",
        "def pvc():\n",
        "    currentPlayer = 1\n",
        "    \"\"\"while True:\n",
        "        try:\n",
        "            order = int(input('Enter to play 1st or 2nd: '))\n",
        "            if not (order == 1 or order == 2):\n",
        "                print('Please pick 1 or 2')\n",
        "            else:\n",
        "                break\n",
        "        except(KeyError, ValueError):\n",
        "            print('Enter a number')\n",
        "\n",
        "    Clearboard(board)\n",
        "    if order == 2:\n",
        "        currentPlayer = -1\n",
        "    else:\n",
        "        currentPlayer = 1\"\"\"\n",
        "\n",
        "    while not (boardFull(board) or gameWon(board)):\n",
        "        makeMove(board, currentPlayer, 1)\n",
        "        currentPlayer *= -1\n",
        "        makeMove(board, currentPlayer, -1)\n",
        "        currentPlayer *= 1\n",
        "\n",
        "    printResult(board)\n",
        "\n",
        "# Driver Code\n",
        "print(\"=================================================\")\n",
        "print(\"TIC-TAC-TOE using MINIMAX with MIN MAX OVER ALPHA-BETA Pruning\")\n",
        "print(\"=================================================\")\n",
        "pvc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af25488d",
      "metadata": {
        "id": "af25488d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e8a8ec",
      "metadata": {
        "id": "19e8a8ec"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}